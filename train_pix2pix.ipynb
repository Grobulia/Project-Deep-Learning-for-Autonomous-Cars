{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yr_FNga052_"
      },
      "source": [
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KF0KChR0_HX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TikhpVt1MPc"
      },
      "source": [
        "## Discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZmbLcW00xJg"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_src_image = Input(shape=image_shape)\n",
        "\t# target image input\n",
        "\tin_target_image = Input(shape=image_shape)\n",
        "\t# concatenate images channel-wise\n",
        "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# # C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t # second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\tpatch_out = Activation('sigmoid')(d)\n",
        "\t# define model\n",
        "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxSnNi8n1bPD"
      },
      "source": [
        "## Encoder-decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1bkRbx1oZN"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7t5SST1aat"
      },
      "source": [
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add downsampling layer\n",
        "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# conditionally add batch normalization\n",
        "\tif batchnorm:\n",
        "\t\tg = BatchNormalization()(g, training=True)\n",
        "\t# leaky relu activation\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\treturn g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvOX1Fsk1sSj"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlHvQFPW1ris"
      },
      "source": [
        "# define a decoder block\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add upsampling layer\n",
        "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# add batch normalization\n",
        "\tg = BatchNormalization()(g, training=True)\n",
        "\t# conditionally add dropout\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.5)(g, training=True)\n",
        "\t# merge with skip connection\n",
        "\tg = Concatenate()([g, skip_in])\n",
        "\t# relu activation\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8eQqOfDZCRb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0hrPHSw1ynv"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Zv5_ig11hm"
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(image_shape=(96,96,3)):\n",
        "\t# weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "  in_image = Input(shape=image_shape)\n",
        "\t# encoder model\n",
        "  e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "  e2 = define_encoder_block(e1, 128)\n",
        "  e3 = define_encoder_block(e2, 256)\n",
        "  #e4 = define_encoder_block(e3, 512)\n",
        "  #e5 = define_encoder_block(e4, 512)\n",
        "  #e6 = define_encoder_block(e5, 512)\n",
        "  #e7 = define_encoder_block(e6, 512)\n",
        "  # bottleneck, no batch norm and relu\n",
        "  b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e3)\n",
        "  b = Activation('relu')(b)\n",
        "  # decoder model\n",
        "  #d1 = decoder_block(b, e7, 512)\n",
        "  #d2 = decoder_block(d1, e6, 512)\n",
        "  #d3 = decoder_block(b, e5, 512)\n",
        "  #d4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "  d5 = decoder_block(b, e3, 256, dropout=False)\n",
        "  d6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "  d7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "  # output\n",
        "  g = Conv2DTranspose(3, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
        "  out_image = Activation('tanh')(g)\n",
        "  # define model\n",
        "  model = Model(in_image, out_image)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YWwVtua2KAN"
      },
      "source": [
        "## Combined GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxIQEExK1_m4"
      },
      "source": [
        "def define_gan(g_model, d_model, image_shape):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tfor layer in d_model.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\t# define the source image\n",
        "\tin_src = Input(shape=image_shape)\n",
        "\t# connect the source image to the generator input\n",
        "\tgen_out = g_model(in_src)\n",
        "\t# connect the source input and generator output to the discriminator input\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\t# src image as input, generated image and classification output\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUcIa4PG2Zc5"
      },
      "source": [
        "## Training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGPLuQ-i2g0I"
      },
      "source": [
        "### Load and prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kcPsX6v2Y_l"
      },
      "source": [
        "def load_real_samples(filename_gw, filename_bw):\n",
        "\t# load compressed arrays\n",
        "  data_gw = load(filename_gw) #good weather data\n",
        "  data_bw = load(filename_bw) #bad weather data\n",
        "\t# unpack arrays\n",
        "  X1, X2 = data_gw, data_bw\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "  X1 = (X1 - 127.5) / 127.5\n",
        "  X2 = (X2 - 127.5) / 127.5\n",
        "  return [X1, X2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajn6gkBu2k0e"
      },
      "source": [
        "### Real samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vq-Ialc2kkM"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# choose random instances\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZWWnAxG2xfg"
      },
      "source": [
        "### Fake samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_svFrzL28Dv"
      },
      "source": [
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(samples)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAhWrPHC3Hjt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORyWIoo_3H0w"
      },
      "source": [
        "# train pix2pix models\n",
        "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\t# update discriminator for real samples\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\t# update discriminator for generated samples\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\t# update the generator\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\t\t# summarize model performance\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOnub39835tu"
      },
      "source": [
        "## Run Everything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MsEzNRMf352b",
        "outputId": "c2d35789-4de8-4d47-d5f0-a5c4e0716dc7"
      },
      "source": [
        "# load image data\n",
        "dataset = load_real_samples('/content/drive/MyDrive/Autonomous cars/images_rgb_snow.npy','/content/drive/MyDrive/Autonomous cars/images_rgb_no_snow.npy')\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "# define the models\n",
        "d_model = define_discriminator(image_shape)\n",
        "g_model = define_generator(image_shape)\n",
        "# define the composite model\n",
        "gan_model = define_gan(g_model, d_model, image_shape)\n",
        "# train model\n",
        "train(d_model, g_model, gan_model, dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded (6000, 96, 96, 3) (6000, 96, 96, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">1, d1[0.315] d2[1.064] g[39.911]\n",
            ">2, d1[0.300] d2[0.559] g[37.723]\n",
            ">3, d1[0.271] d2[0.310] g[36.839]\n",
            ">4, d1[0.290] d2[0.230] g[35.106]\n",
            ">5, d1[0.220] d2[0.239] g[33.791]\n",
            ">6, d1[0.123] d2[0.147] g[32.013]\n",
            ">7, d1[0.177] d2[0.101] g[31.828]\n",
            ">8, d1[0.106] d2[0.119] g[32.083]\n",
            ">9, d1[0.146] d2[0.176] g[28.258]\n",
            ">10, d1[0.142] d2[0.228] g[28.330]\n",
            ">11, d1[0.168] d2[0.071] g[27.091]\n",
            ">12, d1[0.062] d2[0.061] g[26.242]\n",
            ">13, d1[0.031] d2[0.047] g[24.896]\n",
            ">14, d1[0.020] d2[0.036] g[24.957]\n",
            ">15, d1[0.111] d2[0.196] g[22.761]\n",
            ">16, d1[0.152] d2[0.035] g[22.608]\n",
            ">17, d1[0.046] d2[0.064] g[22.057]\n",
            ">18, d1[0.040] d2[0.050] g[22.725]\n",
            ">19, d1[0.018] d2[0.035] g[23.072]\n",
            ">20, d1[0.040] d2[0.058] g[22.862]\n",
            ">21, d1[0.029] d2[0.028] g[20.768]\n",
            ">22, d1[0.219] d2[0.657] g[22.103]\n",
            ">23, d1[1.599] d2[0.095] g[18.189]\n",
            ">24, d1[0.101] d2[0.376] g[18.831]\n",
            ">25, d1[0.103] d2[0.116] g[17.164]\n",
            ">26, d1[0.187] d2[0.328] g[17.473]\n",
            ">27, d1[0.164] d2[0.043] g[19.160]\n",
            ">28, d1[0.032] d2[0.030] g[15.645]\n",
            ">29, d1[0.020] d2[0.039] g[14.726]\n",
            ">30, d1[0.023] d2[0.053] g[16.148]\n",
            ">31, d1[0.034] d2[0.044] g[14.657]\n",
            ">32, d1[0.050] d2[0.140] g[15.278]\n",
            ">33, d1[1.208] d2[1.313] g[15.898]\n",
            ">34, d1[0.169] d2[0.037] g[14.736]\n",
            ">35, d1[0.469] d2[0.169] g[10.768]\n",
            ">36, d1[0.402] d2[0.362] g[17.523]\n",
            ">37, d1[0.079] d2[0.073] g[16.085]\n",
            ">38, d1[0.140] d2[0.066] g[12.319]\n",
            ">39, d1[0.036] d2[0.095] g[13.451]\n",
            ">40, d1[0.100] d2[0.120] g[12.090]\n",
            ">41, d1[0.043] d2[0.078] g[13.241]\n",
            ">42, d1[0.149] d2[0.500] g[12.453]\n",
            ">43, d1[1.544] d2[0.103] g[9.265]\n",
            ">44, d1[0.133] d2[0.780] g[10.152]\n",
            ">45, d1[0.582] d2[0.105] g[16.370]\n",
            ">46, d1[0.154] d2[0.157] g[12.289]\n",
            ">47, d1[0.110] d2[0.132] g[12.494]\n",
            ">48, d1[0.071] d2[0.066] g[13.524]\n",
            ">49, d1[0.041] d2[0.054] g[16.717]\n",
            ">50, d1[0.093] d2[0.088] g[14.999]\n",
            ">51, d1[0.030] d2[0.048] g[14.556]\n",
            ">52, d1[0.736] d2[2.464] g[8.297]\n",
            ">53, d1[0.140] d2[0.414] g[13.101]\n",
            ">54, d1[0.885] d2[0.293] g[9.601]\n",
            ">55, d1[0.295] d2[0.459] g[8.157]\n",
            ">56, d1[0.386] d2[0.272] g[8.478]\n",
            ">57, d1[0.316] d2[0.312] g[9.664]\n",
            ">58, d1[0.232] d2[0.171] g[13.759]\n",
            ">59, d1[0.446] d2[0.394] g[8.137]\n",
            ">60, d1[0.090] d2[0.126] g[10.909]\n",
            ">61, d1[0.372] d2[0.206] g[9.894]\n",
            ">62, d1[0.363] d2[0.615] g[8.036]\n",
            ">63, d1[0.242] d2[0.125] g[8.504]\n",
            ">64, d1[0.067] d2[0.086] g[12.668]\n",
            ">65, d1[0.068] d2[0.068] g[12.421]\n",
            ">66, d1[0.133] d2[0.089] g[11.590]\n",
            ">67, d1[0.060] d2[0.111] g[10.555]\n",
            ">68, d1[0.449] d2[1.346] g[7.591]\n",
            ">69, d1[0.151] d2[0.085] g[11.660]\n",
            ">70, d1[0.754] d2[0.285] g[6.705]\n",
            ">71, d1[0.443] d2[0.988] g[6.709]\n",
            ">72, d1[0.156] d2[0.158] g[9.264]\n",
            ">73, d1[0.412] d2[0.156] g[8.572]\n",
            ">74, d1[0.222] d2[0.237] g[8.622]\n",
            ">75, d1[0.085] d2[0.127] g[9.846]\n",
            ">76, d1[0.288] d2[0.169] g[6.654]\n",
            ">77, d1[0.059] d2[0.131] g[10.270]\n",
            ">78, d1[0.672] d2[0.363] g[6.485]\n",
            ">79, d1[0.058] d2[0.128] g[10.944]\n",
            ">80, d1[0.031] d2[0.051] g[13.097]\n",
            ">81, d1[0.098] d2[0.051] g[9.009]\n",
            ">82, d1[0.231] d2[0.122] g[10.025]\n",
            ">83, d1[0.244] d2[0.185] g[7.032]\n",
            ">84, d1[0.023] d2[0.083] g[12.175]\n",
            ">85, d1[0.063] d2[0.053] g[10.109]\n",
            ">86, d1[0.149] d2[0.071] g[8.703]\n",
            ">87, d1[0.886] d2[1.386] g[4.966]\n",
            ">88, d1[0.398] d2[0.373] g[6.124]\n",
            ">89, d1[0.079] d2[0.128] g[9.384]\n",
            ">90, d1[0.033] d2[0.054] g[16.059]\n",
            ">91, d1[0.876] d2[0.224] g[5.814]\n",
            ">92, d1[0.090] d2[0.259] g[9.515]\n",
            ">93, d1[0.114] d2[0.092] g[13.437]\n",
            ">94, d1[0.749] d2[0.313] g[4.915]\n",
            ">95, d1[0.165] d2[0.405] g[5.629]\n",
            ">96, d1[0.028] d2[0.086] g[14.265]\n",
            ">97, d1[0.031] d2[0.044] g[10.311]\n",
            ">98, d1[0.624] d2[0.265] g[5.277]\n",
            ">99, d1[0.020] d2[0.246] g[8.915]\n",
            ">100, d1[0.042] d2[0.053] g[10.489]\n",
            ">101, d1[0.690] d2[0.427] g[5.363]\n",
            ">102, d1[0.013] d2[0.156] g[14.724]\n",
            ">103, d1[0.015] d2[0.053] g[15.147]\n",
            ">104, d1[1.192] d2[0.234] g[6.506]\n",
            ">105, d1[0.428] d2[0.430] g[6.559]\n",
            ">106, d1[0.046] d2[0.144] g[9.327]\n",
            ">107, d1[0.515] d2[0.203] g[5.444]\n",
            ">108, d1[0.146] d2[0.254] g[7.119]\n",
            ">109, d1[0.151] d2[0.141] g[7.482]\n",
            ">110, d1[0.017] d2[0.089] g[12.694]\n",
            ">111, d1[0.747] d2[0.337] g[6.411]\n",
            ">112, d1[0.156] d2[0.218] g[6.592]\n",
            ">113, d1[0.017] d2[0.094] g[13.423]\n",
            ">114, d1[0.018] d2[0.050] g[12.212]\n",
            ">115, d1[0.027] d2[0.038] g[11.918]\n",
            ">116, d1[0.377] d2[0.128] g[6.664]\n",
            ">117, d1[0.012] d2[0.286] g[11.348]\n",
            ">118, d1[0.015] d2[0.043] g[14.544]\n",
            ">119, d1[1.029] d2[0.296] g[6.441]\n",
            ">120, d1[0.281] d2[0.453] g[7.552]\n",
            ">121, d1[0.349] d2[0.259] g[5.448]\n",
            ">122, d1[0.063] d2[0.176] g[7.106]\n",
            ">123, d1[0.027] d2[0.074] g[12.754]\n",
            ">124, d1[0.512] d2[0.409] g[6.146]\n",
            ">125, d1[0.100] d2[0.139] g[7.823]\n",
            ">126, d1[0.094] d2[0.085] g[8.753]\n",
            ">127, d1[0.024] d2[0.074] g[10.694]\n",
            ">128, d1[0.985] d2[0.459] g[7.176]\n",
            ">129, d1[0.511] d2[0.339] g[6.298]\n",
            ">130, d1[0.123] d2[0.187] g[6.319]\n",
            ">131, d1[0.100] d2[0.134] g[9.407]\n",
            ">132, d1[0.321] d2[0.198] g[7.047]\n",
            ">133, d1[0.025] d2[0.117] g[12.834]\n",
            ">134, d1[0.153] d2[0.151] g[11.259]\n",
            ">135, d1[0.072] d2[0.128] g[8.701]\n",
            ">136, d1[0.980] d2[0.479] g[6.251]\n",
            ">137, d1[0.330] d2[0.269] g[6.207]\n",
            ">138, d1[0.012] d2[0.152] g[12.969]\n",
            ">139, d1[0.239] d2[0.109] g[8.334]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-8a2137f00455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-b5c4f66a5aa8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(d_model, g_model, gan_model, dataset, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mX_fakeB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;31m# update discriminator for real samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# update discriminator for generated samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fakeB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                                                     class_weight)\n\u001b[1;32m   1799\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpmhNcFDHFW5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjq3yKR1HHZR",
        "outputId": "f04907e1-977d-4df2-da4a-ec6d85e44493"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwoFXaWqHJPg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}